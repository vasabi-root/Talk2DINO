<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="Talking to DINO: Bridging Self-Supervised Vision Backbones with Language for Open-Vocabulary Segmentation">
  <meta name="keywords" content="open-vocabulary segmentation, DINO, CLIP, open-world perception">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Talking to DINO: Bridging Self-Supervised Vision Backbones with Language for Open-Vocabulary Segmentation</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/logo.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<!-- More Research -->
  <nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>
    <div class="navbar-menu">
      <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
        
        <!-- <a class="navbar-item" href="https://concept-fusion.github.io">
        <span class="icon">
            <i class="fas fa-home"></i>
        </span>
        </a> -->
  
        <!-- <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link">
            Related Research
          </a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="Example.com">
              FExample
            </a>
          </div>
        </div> -->
      </div>
  
    </div>
  </nav>

<!-- More Research
<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="#">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>
      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="#">
            Project 1
          </a>
        </div>
      </div>
    </div>
  </div>
</nav>
-->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <header class="column has-text-centered">
          <img src="./static/images/logo.png" alt="Talk2DINO Logo" class="logo-image">
          <h1 class="title is-1 publication-title">
            <p class="title publication-title">Bridging Self-Supervised Vision Backbones with Language for Open-Vocabulary Segmentation</p>
            <p class="is-size-4 publication-awards">ICCV 2025</p>
          </h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://lucabarsellotti.github.io/">Luca Barsellotti</a><sup>*1</sup>,
              </span>
              <span class="author-block">
                <a href="https://lorebianchi98.github.io/">Lorenzo Bianchi</a><sup>*2,3</sup>,
              </span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/nicola-messina-a33848164/">Nicola Messina</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/fabio-carrara-b28a2b111/">Fabio Carrara</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://aimagelab.ing.unimore.it/imagelab/person.asp?idpersona=90">Marcella Cornia</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.lorenzobaraldi.com/">Lorenzo Baraldi</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://fabriziofalchi.it">Fabrizio Falchi</a><sup>2</sup>
            </span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/rita-cucchiara-a4653a13/">Rita Cucchiara</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of Modena and Reggio Emilia, Italy</span>
            <span class="author-block"><sup>2</sup>ISTI CNR</span>
            <span class="author-block"><sup>3</sup>University of Pisa, Italy</span>
          </div>


          <div class="is-size-5 publication-authors">
            <span class="author-block">* Equal contribution</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <!-- <span class="link-block">
                <a href="https://arxiv.org/abs/INSERIRELINK"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->
              <span class="link-block">
                <a href="http://arxiv.org/abs/2411.19331"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!--
                <span class="link-block">
                  <a href="https://cvpr.thecvf.com/media/PosterPDFs/CVPR%202024/29694.png?t=1717055323.7435858"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-image"></i>
                  </span>
                  <span>Poster</span>
                </a>
              </span>
              -->
              <!-- Video Link.
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v="
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/lorebianchi98/Talk2DINO"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Hugging Face Link. -->
              <span class="link-block">
                <a href="https://huggingface.co/papers/2411.19331"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      ðŸ¤—
                  </span>
                  <span>Hugging Face</span>
                </a>
              </span>
              <!-- Demo -->
              <span class="link-block">
                <a href="https://huggingface.co/spaces/lorebianchi98/Talk2DINO"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-desktop"></i>
                  </span>
                  <span>Demo</span>
                </a>
              <!-- Models Link. -->
              <span class="link-block">
                <a href="https://github.com/lorebianchi98/Talk2DINO/tree/main/weights"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Models</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/lorebianchi98/FG-OVD/tree/main/benchmarks"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a> -->
              <!-- Video Link. 
              
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=3AIbqptBhmo"
                class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
            -->
            </div>
          </div>
        </header>
      </div>
    </div>
  </div>
</section>

<!-- Carousel.
<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-1"></div>
        <div class="item item-2"></div>
      </div>
    </div>
  </div>
</section>
-->

  <!-- Video Summary -->
  <section class="teaser is-light">
    <div class="container is-max-desktop">
      <!-- Paper video. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Video Summary</h2>
          <figure class="content publication-video image is-16by9">
            <iframe class="has-ratio" src="https://www.youtube.com/embed/RxkdeFxEehg" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
          </figure>
        </div>
      </div>
      <!--/ Paper video. -->
    </div>
  </section>

 <!-- Teaser. -->
 <section class="section hero teaser">
  <div class="container is-max-desktop has-text-centered">
    <div class="content">
      <h2 class="title is-3">Overview</h2>
      <figure class="hero-body">
        <img src="./static/images/teaser.png" alt="Talk2DINO pipeline" class="teaser-image">
      </figure>
    </div>
  </div>
</section>

<section class="section hero is-light">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Open-Vocabulary Segmentation (OVS) aims at segmenting images from free-form textual concepts without predefined training classes. While existing vision-language models such as CLIP can generate segmentation masks by leveraging coarse spatial information from Vision Transformers, they face challenges in spatial localization due to their global alignment of image and text features. Conversely, self-supervised visual models like DINO excel in fine-grained visual encoding but lack integration with language.
          </p>
          <p>
            To bridge this gap, we present Talk2DINO, a novel hybrid approach that combines the spatial accuracy of DINOv2 with the language understanding of CLIP. Our approach aligns the textual embeddings of CLIP to the patch-level features of DINOv2 through a learned mapping function without the need to fine-tune the underlying backbones. At training time, we exploit the attention maps of DINOv2 to selectively align local visual patches with textual embeddings.
          </p>
          <p>
             We show that the powerful semantic and localization abilities of Talk2DINO can enhance the segmentation process, resulting in more natural and less noisy segmentations, and that our approach can also effectively distinguish foreground objects from the background. Experimental results demonstrate that Talk2DINO achieves state-of-the-art performance across several unsupervised OVS benchmarks..</p>
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>
<!-- Predictions. -->
<section class="section" id="results">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width has-text-centered">

        <h2 class="title is-3">Examples</h2>
        <figure>
          <img src="./static/images/qualitatives.png" alt="Results examples" class="teaser-image"><br><br>
          <caption>Qualitative results of Talk2DINO in comparison with FreeDA, ProxyCLIP, and CLIP-DINOiser.</caption>
        </figure>
        <br>
        
        <h2 class="title is-3">Results</h2>
        <figure>
          <img src="./static/images/ovs_results.png" alt="Results examples" class="teaser-image"><br><br>
          <caption>Comparison with unsupervised OVS models on Pascal VOC, Pascal Context, COCO Stuff, COCO Object, Cityscapes, and ADE20K. For each method, we specify the visual backbone used, along with whether it is frozen or fine-tuned. We report both the variants with and without background for Pascal VOC (V21 and V20) and Pascal Context (C60 and C59). Best results with and without mask refinement are highlighted in bold, overall best results are underlined.</caption>
        </figure>
        
      </div>
    </div>
  </div>
</section>


<!-- Results -->
<!-- <section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Research questions</h2>
        <div class="content has-text-justified">
          </div>
      </div>
    </div>
  </div>
</section> -->
<!-- Concurrent Work.
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Links</h2>
        <div class="content has-text-justified">
          <p></p>
        </div>
      </div>
    </div>
  </div>
</section>
-->


<section class="section hero is-light id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{barsellotti2025talking,
  title={Talking to dino: Bridging self-supervised vision backbones with language for open-vocabulary segmentation},
  author={Barsellotti, Luca and Bianchi, Lorenzo and Messina, Nicola and Carrara, Fabio and Cornia, Marcella and Baraldi, Lorenzo and Falchi, Fabrizio and Cucchiara, Rita},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={22025--22035},
  year={2025}
}</code></pre>
  </div>
</section>


<section class="section" id="ack">
  <div class="container is-max-desktop content">
    <h2 class="title">Acknowledgements</h2>
    <p>
      <!-- <a href="#" target="_blank"> -->
        <img src="./static/images/muces.png" alt="MUCES Project Logo" width="200">
      <!-- </a> -->
      This work has received financial support by the European Union &mdash; Next Generation EU, Mission 4 Component 1
      CUP B53D23026090001 and E53D23016290001 (a MUltimedia platform for Content Enrichment and Search in audiovisual archives &mdash; MUCES PRIN 2022 PNRR P2022BW7CW).
    </p>
    <p>
      <a href="https://www.sun-xr-project.eu/" target="_blank"><img src="./static/images/sun.png" alt="SUN Project Logo" width="200"></a>
      This work has received financial support by the Horizon Europe Research & Innovation Programme under Grant agreement N. 101092612 (Social and hUman ceNtered XR - SUN project).
    </p>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link" href="https://github.com/fabiocarrara" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This website is borrowed from <a
              href="https://github.com/nerfies/nerfies.github.io">nerfies</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>

